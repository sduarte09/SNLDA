{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXSgAEfcsgeV"
      },
      "source": [
        "# \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ERA5-Land Magdalena River Basin Daily: Dynamical system properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us8XS06eUZYm"
      },
      "source": [
        "In this document we will calculate the clasical errors between ERA5 data and local rainfall gauge stations using standard metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mkTCPyIvcabz"
      },
      "source": [
        "## 0. Import Libraries and define functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PWUCYKmucelI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import netCDF4 as nc\n",
        "from math import sqrt\n",
        "import sklearn.metrics # Machine Learning in Python\n",
        "import sklearn.neighbors # Machine Learning in Python\n",
        "import datetime as dt\n",
        "import scipy\n",
        "import math\n",
        "import warnings # Ignore not important warnings\n",
        "from numba import jit, cuda # Use GPU\n",
        "import time\n",
        "from toolz import curry # List processing tools and functional utilities\n",
        "from operator import sub # Standard operators as functions\n",
        "import nolds # Nonlinear measures for dynamical systems\n",
        "from nolitsa import dimension, delay\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "@jit(target_backend =\"cuda\")\n",
        "def delay_own2(x):\n",
        "    n = len(x)\n",
        "    y = x - np.mean(x)  # Center the data\n",
        "    # Pre-allocate memory for better performance (avoids redundant allocations)\n",
        "    r = np.zeros(n)\n",
        "    auto = np.zeros(n)\n",
        "    # Calculate correlations using a loop for potential CUDA kernel compatibility\n",
        "    for k in range(n):\n",
        "        r[k] = np.dot(y[:n - k], y[-(n - k):])  # Efficient dot product for correlation\n",
        "    # Calculate autocorrelation\n",
        "    auto[:] = r / (np.var(x) * (np.arange(n, 0, -1)))\n",
        "    # Find the first delay where the autocorrelation changes sign twice\n",
        "    da = 0\n",
        "    while da < n - 2 and auto[da] * auto[da + 1] > 0:\n",
        "        da += 1\n",
        "    return da + 1  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def delay_own(x):\n",
        "    # Returns the optimal Time-Delay from a time series\n",
        "    # Use the autocorrelation function and the mutual information score\n",
        "    da=0;dm=0\n",
        "    n = len(x)\n",
        "    y = x-x.mean()   \n",
        "    r = np.correlate(y, y, mode = 'full')[-n:]\n",
        "    assert np.allclose(r, np.array([(y[:n-k]*y[-(n-k):]).sum() for k in range(n)]))\n",
        "    auto = r/(x.var()*(np.arange(n, 0, -1)))\n",
        "    while (auto[da]*auto[da+1])>0:\n",
        "        da=da+1\n",
        "    da=da+1    \n",
        "    #while sklearn.metrics.mutual_info_score(None,None,contingency=np.histogram2d(x, np.roll(x,dm),20)[0])>=sklearn.metrics.mutual_info_score(None,None, contingency=np.histogram2d(x, np.roll(x,dm+1),20)[0]):\n",
        "    #    dm=dm+1\n",
        "    #lag=min(da,dm)+1\n",
        "    return da #lag       \n",
        "\n",
        "def delay_tot(x):\n",
        "    # Returns the optimal Time-Delay from a time series\n",
        "    # Use the autocorrelation function and the mutual information score\n",
        "    da=0;dm=0\n",
        "    n = len(x)\n",
        "    y = x-x.mean()   \n",
        "    r = np.correlate(y, y, mode = 'full')[-n:]\n",
        "    assert np.allclose(r, np.array([(y[:n-k]*y[-(n-k):]).sum() for k in range(n)]))\n",
        "    auto = r/(x.var()*(np.arange(n, 0, -1)))\n",
        "    while (auto[da]*auto[da+1])>0:\n",
        "        da=da+1\n",
        "    da=da+1    \n",
        "    while sklearn.metrics.mutual_info_score(None,None,contingency=np.histogram2d(x, np.roll(x,dm),20)[0])>=sklearn.metrics.mutual_info_score(None,None, contingency=np.histogram2d(x, np.roll(x,dm+1),20)[0]):\n",
        "        dm=dm+1\n",
        "    lag=min(da,dm)\n",
        "    return lag       \n",
        "\n",
        "def global_false_nearest_neighbors(x, lag, min_dims=1, max_dims=15, **cutoffs):\n",
        "    # Created by hsharrison\n",
        "    # pypsr taken from https://github.com/hsharrison/pypsr MIT License\n",
        "    x = _vector(x)\n",
        "    dimensions = np.arange(min_dims, max_dims + 1)\n",
        "    false_neighbor_pcts = np.array([_gfnn(x, lag, n_dims, **cutoffs) for n_dims in dimensions])\n",
        "    return dimensions, false_neighbor_pcts\n",
        "\n",
        "def _gfnn(x, lag, n_dims, **cutoffs):\n",
        "    # Created by hsharrison\n",
        "    # pypsr taken from https://github.com/hsharrison/pypsr MIT License\n",
        "    # Global false nearest neighbors at a particular dimension.\n",
        "    # Returns percent of all nearest neighbors that are still neighbors when the next dimension is unfolded.\n",
        "    # Neighbors that can't be embedded due to lack of data are not counted in the denominator.\n",
        "    offset = lag*n_dims\n",
        "    is_true_neighbor = _is_true_neighbor(x, _radius(x), offset)\n",
        "    return np.mean([\n",
        "        not is_true_neighbor(indices, distance, **cutoffs)\n",
        "        for indices, distance in _nearest_neighbors(reconstruct(x, lag, n_dims))\n",
        "        if (indices + offset < x.size).all()\n",
        "    ])\n",
        "      \n",
        "@curry \n",
        "def _is_true_neighbor(x, attractor_radius, offset, indices, distance,relative_distance_cutoff=15, relative_radius_cutoff=2):\n",
        "    # Created by hsharrison\n",
        "    # pypsr taken from https://github.com/hsharrison/pypsr MIT License\n",
        "    distance_increase = np.abs(sub(*x[indices + offset])) \n",
        "    return (distance_increase / distance < relative_distance_cutoff and\n",
        "            distance_increase / attractor_radius < relative_radius_cutoff)\n",
        " \n",
        "@jit \n",
        "def _distance(y):\n",
        "    distances, indices = sklearn.neighbors.NearestNeighbors(n_neighbors=2, algorithm='kd_tree').fit(y).kneighbors(y)\n",
        "    return distances, indices\n",
        "\n",
        "def _nearest_neighbors(y):\n",
        "    # Created by hsharrison\n",
        "    # pypsr taken from https://github.com/hsharrison/pypsr MIT License\n",
        "    distances, indices = _distance(y)\n",
        "    for distance, index in zip(distances, indices):\n",
        "        yield index, distance[1]\n",
        "\n",
        "@jit \n",
        "def _radius(x):\n",
        "    # Created by hsharrison\n",
        "    # pypsr taken from https://github.com/hsharrison/pypsr MIT License\n",
        "    return np.sqrt(((x - x.mean())**2).mean())\n",
        "\n",
        "def reconstruct(x, lag, n_dims):\n",
        "    # create the delayed vector from a time series\n",
        "    x = _vector(x)\n",
        "    lags = lag * np.arange(n_dims)\n",
        "    return np.vstack(x[lag:lag - lags[-1] or None] for lag in lags).transpose()\n",
        "\n",
        "def deconstruct(x, lag, n_dims):\n",
        "    # create the time series from a delayed vector\n",
        "    dec=np.empty(len(x)+lag*(n_dims-1))* np.nan\n",
        "    dec[:len(x)]=x[:,0]\n",
        "    dec[len(x):]=x[-lag*(n_dims-1):,-1]\n",
        "    return dec\n",
        "\n",
        "def _vector(x):\n",
        "    # Created by hsharrison\n",
        "    # pypsr taken from https://github.com/hsharrison/pypsr MIT License\n",
        "    x = np.squeeze(x)\n",
        "    if x.ndim != 1:\n",
        "        raise ValueError('x(t) must be a 1-dimensional signal')\n",
        "    return x   \n",
        "\n",
        "def dynamics_analysis(x):   \n",
        "    # Chaos analyis of the time series\n",
        "    # Use Eckmann et al algorithm for lyapunov exponents and FNN for embedding dimension\n",
        "    # Returns the time delay, the embedding dimension and the lyapunov spectrum\n",
        "    #\n",
        "    x=x.flatten()\n",
        "    lag=delay_tot(x)\n",
        "    mmax=2*int(np.floor(2*math.log10(len(x))))+1 \n",
        "    fnn=global_false_nearest_neighbors(x, lag, min_dims=1, max_dims=mmax)  \n",
        "    f_th=0.20\n",
        "    if len(fnn[1][fnn[1]<=f_th])!=0: \n",
        "        if 0 in fnn[1]:\n",
        "            m1=np.where(fnn[1]==0)[0][0]\n",
        "        else:\n",
        "            m1=np.where(fnn[1]<=f_th)[0][0]  \n",
        "        lyapunov=nolds.lyap_e(x,emb_dim=m1,matrix_dim=m1,tau=lag)\n",
        "    else:\n",
        "        m1=-99\n",
        "        lyapunov=[-99]\n",
        "    hurst=nolds.hurst_rs(x)\n",
        "    return lag,m1,lyapunov,hurst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCJMKJj1Xpwx"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Local Data CSV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukHo1ybGrvmM",
        "outputId": "fe67fc95-decf-446d-f880-25e2ac31f95f"
      },
      "outputs": [],
      "source": [
        "# CSV Paths\n",
        "data_path=\"Data/Local CSV/Precipitation 1980-2020 data filled 1.csv\" \n",
        "coords_path=\"Data/Local CSV/Precipitation 1980-2020 coord filled.csv\" \n",
        "# Import data\n",
        "stations=pd.read_csv(data_path,sep=',',index_col=\"Fecha\",parse_dates=True)\n",
        "coords=pd.read_csv(coords_path,sep=';',index_col=\"Station\")\n",
        "# Longitude Coords\n",
        "if  (coords['Long']<0).any():\n",
        "    coords['Long']=coords['Long']+360   \n",
        "# Dates obtained from CSV\n",
        "dates=stations.index "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **ERA-Land Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NC path\n",
        "eraland_path=\"Data/ERALand NC/precipitation_eraland_d2.nc\"\n",
        "# Check NetCDF Time\n",
        "eralandnc = nc.Dataset(eraland_path)\n",
        "time_unit=eralandnc.variables['time'].units \n",
        "time_cal=eralandnc.variables['time'].calendar\n",
        "time_valh=eralandnc.variables['time'][:]\n",
        "time_his=nc.num2date(time_valh,units=time_unit,calendar=time_cal)\n",
        "time_his=sorted([dt.datetime.strptime(k.strftime('%Y-%m-%d %H:%M'),'%Y-%m-%d %H:%M') for k in time_his])\n",
        "# NetCDF grid data\n",
        "nc_lat_eraland=eralandnc.variables['latitude'][:]\n",
        "nc_lon_eraland=eralandnc.variables['longitude'][:]\n",
        "if  (nc_lon_eraland<0).any():\n",
        "    nc_lon_eraland=nc_lon_eraland+360   \n",
        "# Precipitation variable name\n",
        "var_type4=list(eralandnc.variables.keys())[-1]    \n",
        "# Load data\n",
        "eraland=eralandnc.variables[var_type4][:,:,:].data\n",
        "eralandnc.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Basin Mask 0.10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Basin Mask 0.10 (.nc file)\n",
        "rain_nc=\"Data/Magdalena/GIS/Basin/Basin_ext_010.nc\"\n",
        "basin = nc.Dataset(rain_nc)\n",
        "basin_lat_010=basin.variables['lat'][:]\n",
        "basin_lon_010=basin.variables['lon'][:]\n",
        "var_type=list(basin.variables.keys())[0]  \n",
        "cells_x_010=np.array(basin_lat_010)[:]\n",
        "cells_y_010=np.array(basin_lon_010)[:]\n",
        "mascara=np.array(basin.variables[var_type][:,:])\n",
        "mask=mascara!=mascara[1,1]\n",
        "mask=np.flip(mask*1,axis=0).astype('float64')\n",
        "mask[mask==0]=np.nan\n",
        "mask_st=mask.reshape((1, mask.shape[0],mask.shape[1]))\n",
        "mask_basin_010=mask_st.reshape(mask_st.shape[1],mask_st.shape[2])\n",
        "basin.close()\n",
        "# Find coordinates where basin exists in mask\n",
        "basin_coords_010=np.where(mask_basin_010==1)\n",
        "# Find position of coordinates in datasets arrays\n",
        "basin_true_longs_010=basin_lon_010.data[basin_coords_010[1]]+360\n",
        "basin_true_lats_010=np.flip(basin_lat_010.data)[basin_coords_010[0]]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dynamical system properties"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Local Gauge Stations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-allocate results\n",
        "sta_results=coords.copy().drop('Length',axis=1)\n",
        "sta_results[\"delay\"]=np.nan\n",
        "sta_results[\"dim_fnn\"]=np.nan\n",
        "sta_results[\"hurst\"]=np.nan\n",
        "sta_results[\"lyapunov_max\"]=np.nan\n",
        "sta_results[\"lyapunov_sum\"]=np.nan\n",
        "stations_names= coords.index\n",
        "# Compute dynamical system properties\n",
        "print(len(stations_names))\n",
        "for ii in range(len(stations_names)):\n",
        "    print(ii)\n",
        "    i=stations_names[ii]\n",
        "    x=stations[i].values\n",
        "    lag,m1,lyapunov,hurst=dynamics_analysis(x)\n",
        "    sta_results[\"delay\"].loc[i]=lag\n",
        "    sta_results[\"dim_fnn\"].loc[i]=m1\n",
        "    sta_results[\"hurst\"].loc[i]=hurst\n",
        "    sta_results[\"lyapunov_max\"].loc[i]=max(lyapunov)\n",
        "    sta_results[\"lyapunov_sum\"].loc[i]=sum(lyapunov)\n",
        "sta_results.to_csv(\"Results/Dynamical system properties/local_stations_daily.csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **ERA-Land Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### Compute properties ######\n",
        "# Pre-allocate results\n",
        "nc_array=np.zeros((eraland.shape[1],eraland.shape[2]))*np.nan\n",
        "delay_array=nc_array.copy()\n",
        "dim_fnn_array=nc_array.copy()\n",
        "dim_afn_array=nc_array.copy()\n",
        "hurst_array=nc_array.copy()\n",
        "dynamics_afn_array=nc_array.copy()\n",
        "dynamics_lyap_array=nc_array.copy()\n",
        "dynamics_hurst_array=nc_array.copy()\n",
        "lyapunov_ma_array=nc_array.copy()\n",
        "lyapunov_sum_array=nc_array.copy()\n",
        "# Iterate over basin pixels\n",
        "for j in range(len(basin_coords_010[0])):\n",
        "    print(str(j)+' of '+str(len(basin_coords_010[0])))\n",
        "    # Array position \n",
        "    x_long=basin_coords_010[0][j]\n",
        "    y_lat=basin_coords_010[1][j]\n",
        "    # Geographic position\n",
        "    look_long=basin_true_longs_010[j]\n",
        "    look_lat=basin_true_lats_010[j]\n",
        "   # ERA5 position:\n",
        "    ## Lat\n",
        "    lat_eraland_pos=np.where((nc_lat_eraland==look_lat))\n",
        "    if len(lat_eraland_pos[0])==0:\n",
        "        continue\n",
        "    lat_eraland=lat_eraland_pos[0]\n",
        "    ## Long\n",
        "    long_eraland_pos=np.where((nc_lon_eraland==look_long))\n",
        "    if len(long_eraland_pos[0])==0:\n",
        "        continue\n",
        "    long_eraland=long_eraland_pos[0]\n",
        "    eraland_value=eraland[:,lat_eraland,long_eraland].flatten()\n",
        "    if int(np.mean(eraland_value))==-32767000:\n",
        "        print('  not available')\n",
        "        continue\n",
        "    ## Calculate\n",
        "    lag,m1,m2,lyapunov,hurst=dynamics_analysis(eraland_value)\n",
        "    ## Store in array\n",
        "    delay_array[lat_eraland,long_eraland]=lag\n",
        "    dim_fnn_array[lat_eraland,long_eraland]=m1\n",
        "    hurst_array[lat_eraland,long_eraland]=hurst\n",
        "    lyapunov_ma_array[lat_eraland,long_eraland]=max(lyapunov)\n",
        "    lyapunov_sum_array[lat_eraland,long_eraland]=sum(lyapunov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### SAVE results TO NC FILE ######\n",
        "# Define Path \n",
        "ncfile = nc.Dataset(\"Results/Dynamical system properties/Eraland_daily.nc\",mode='w',format='NETCDF3_64BIT_OFFSET') \n",
        "# Creating netcdf output and its dimensions\n",
        "lat_dim = ncfile.createDimension('latitude',eraland.shape[1])  \n",
        "lon_dim = ncfile.createDimension('longitude',eraland.shape[2]) \n",
        "ncfile.title=\"eraland\"\n",
        "lat = ncfile.createVariable('latitude', np.float32, ('latitude',))\n",
        "lat.units = idw10nc.variables['latitude'].units\n",
        "lat[:] = nc_lat_eraland\n",
        "lon = ncfile.createVariable('longitude', np.float32, ('longitude',))\n",
        "lon.units = idw10nc.variables['longitude'].units\n",
        "lon[:] = nc_lon_eraland\n",
        "# Define properties\n",
        "properties=['delay','dim_fnn','hurst','lyapunov_max','lyapunov_sum']\n",
        "properties_arrays=[delay_array,dim_fnn_array,hurst_array,lyapunov_ma_array,lyapunov_sum_array]\n",
        "# Compute properties\n",
        "for i in range(len(properties)):\n",
        "    var_nc= ncfile.createVariable(properties[i],np.float64,('latitude','longitude')) \n",
        "    var_nc.missing_value=-9999   \n",
        "    var_nc[:,:] = properties_arrays[i]\n",
        "ncfile.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
