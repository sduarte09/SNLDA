{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXSgAEfcsgeV"
      },
      "source": [
        "# \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Validation ERA-Land Magdalena River Basin Daily: Standard metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "us8XS06eUZYm"
      },
      "source": [
        "In this document we will calculate the clasical errors between ERA-Land data and local rainfall gauge stations using standard metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mkTCPyIvcabz"
      },
      "source": [
        "## 0. Import Libraries and define functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWUCYKmucelI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import netCDF4 as nc\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error, log_loss, mutual_info_score\n",
        "import datetime as dt\n",
        "import scipy\n",
        "import warnings # Ignore not important warnings\n",
        "from tifffile import imsave\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_entropy(targets,predictions,  epsilon=1e-12):\n",
        "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
        "    N = predictions.shape[0]\n",
        "    ce = -np.sum(targets*np.log(predictions))/N\n",
        "    return ce\n",
        "\n",
        "def calc_MI(x, y):\n",
        "    c_xy = np.histogram2d(x, y, 20)[0]\n",
        "    mi=mutual_info_score(None, None, contingency=c_xy)\n",
        "    return mi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCJMKJj1Xpwx"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Local Data CSV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukHo1ybGrvmM",
        "outputId": "fe67fc95-decf-446d-f880-25e2ac31f95f"
      },
      "outputs": [],
      "source": [
        "# CSV Paths\n",
        "data_path=\"Data/Local CSV/Precipitation 1980-2020 data filled 1.csv\" \n",
        "coords_path=\"Data/Local CSV/Precipitation 1980-2020 coord filled.csv\" \n",
        "# Import data\n",
        "stations=pd.read_csv(data_path,sep=',',index_col=\"Fecha\",parse_dates=True)\n",
        "coords=pd.read_csv(coords_path,sep=';',index_col=\"Station\")\n",
        "## Daily to monthly\n",
        "# stations=stations.resample('MS').sum()\n",
        "# Longitude Coords\n",
        "if  (coords['Long']<0).any():\n",
        "    coords['Long']=coords['Long']+360   \n",
        "# Dates obtained from CSV\n",
        "dates=stations.index "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Local Data NetCDF(IDW) - 0.1째x0.1째**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NC path\n",
        "idw10_path=\"Data/Local IDW/IDW_daily_010.nc\"\n",
        "# Check NetCDF Time\n",
        "idw10nc = nc.Dataset(idw10_path)\n",
        "time_unit=idw10nc.variables['time'].units \n",
        "time_cal=idw10nc.variables['time'].calendar\n",
        "time_valh=idw10nc.variables['time'][:]\n",
        "time_his=nc.num2date(time_valh,units=time_unit,calendar=time_cal)\n",
        "time_his=sorted([dt.datetime.strptime(k.strftime('%Y-%m-%d %H:%M'),'%Y-%m-%d %H:%M') for k in time_his])\n",
        "# NetCDF grid data\n",
        "nc_lat_idw010=idw10nc.variables['latitude'][:]\n",
        "nc_lon_idw010=idw10nc.variables['longitude'][:]\n",
        "if  (nc_lon_idw010<0).any():\n",
        "    nc_lon_idw010=nc_lon_idw010+360   \n",
        "# Precipitation variable name\n",
        "var_type2=list(idw10nc.variables.keys())[-1]    \n",
        "# Load data\n",
        "idw10=idw10nc.variables[var_type2][:,:,:].data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **ERA Land Data - 0.1째x0.1째**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NC path\n",
        "eraland_path=\"Data/ERALand NC/precipitation_eraland_d.nc\"\n",
        "# Check NetCDF Time\n",
        "eralandnc = nc.Dataset(eraland_path)\n",
        "time_unit=eralandnc.variables['time'].units \n",
        "time_cal=eralandnc.variables['time'].calendar\n",
        "time_valh=eralandnc.variables['time'][:]\n",
        "time_his=nc.num2date(time_valh,units=time_unit,calendar=time_cal)\n",
        "time_his=sorted([dt.datetime.strptime(k.strftime('%Y-%m-%d %H:%M'),'%Y-%m-%d %H:%M') for k in time_his])\n",
        "# NetCDF grid data\n",
        "nc_lat_eraland=eralandnc.variables['latitude'][:]\n",
        "nc_lon_eraland=eralandnc.variables['longitude'][:]\n",
        "if  (nc_lon_eraland<0).any():\n",
        "    nc_lon_eraland=nc_lon_eraland+360   \n",
        "# Precipitation variable name\n",
        "var_type4=list(eralandnc.variables.keys())[-1]    \n",
        "# Load data\n",
        "eraland=eralandnc.variables[var_type4][:,:,:].data\n",
        "eralandnc.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Error calculation to local stations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Select datasets to compare**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparison datasets\n",
        "dataset_name=['IDW 010','ERA5']\n",
        "dataset=[idw10,eraland]\n",
        "lats=[nc_lat_idw010,nc_lat_eraland]\n",
        "longs=[nc_lon_idw010,nc_lon_eraland]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wQVNlEM8JNcT"
      },
      "source": [
        "#### **Compute Errors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDhQMNkIE0fb"
      },
      "outputs": [],
      "source": [
        "# Metrics to evaluate\n",
        "metrics=['MAE','MSE','RMSE','Correlation','Mutual Information','Cross Entropy']\n",
        "# Possible datasets\n",
        "opt=len(dataset_name)\n",
        "error_options=[]\n",
        "for i in range(opt):\n",
        "    # Load dataset\n",
        "    name=dataset_name[i]\n",
        "    print(name)\n",
        "    data=dataset[i]\n",
        "    lat_set=lats[i]\n",
        "    long_set=longs[i]\n",
        "    # Pre-allocate results\n",
        "    error_stations=coords.copy().drop(['Length'],axis=1)\n",
        "    error_stations[metrics]=np.nan\n",
        "    # Compute Results\n",
        "    stations_names= error_stations.index\n",
        "    for z in stations_names:\n",
        "        cell_lat=1;cell_lon=1\n",
        "        # Get stations location in cell grids \n",
        "        if lat_set[0]<lat_set[1]:\n",
        "            while cell_lat<=len(lat_set):\n",
        "                if (lat_set[cell_lat-1]+lat_set[cell_lat])/2<=error_stations['Lat'][z] and error_stations['Lat'][z]<=(lat_set[cell_lat+1]+lat_set[cell_lat])/2:\n",
        "                    break\n",
        "                cell_lat=cell_lat+1\n",
        "        else:\n",
        "            while cell_lat<=len(lat_set):\n",
        "                if (lat_set[cell_lat+1]+lat_set[cell_lat])/2<=error_stations['Lat'][z] and error_stations['Lat'][z]<=(lat_set[cell_lat-1]+lat_set[cell_lat])/2:\n",
        "                    break\n",
        "                cell_lat=cell_lat+1\n",
        "        while cell_lon<=len(long_set):\n",
        "            if (long_set[cell_lon-1]+long_set[cell_lon])/2<=error_stations['Long'][z] and error_stations['Long'][z]<=(long_set[cell_lon+1]+long_set[cell_lon])/2:\n",
        "                break\n",
        "            cell_lon=cell_lon+1\n",
        "        # Values in the cell where the station is located\n",
        "        cell_values=data[:,cell_lat,cell_lon]\n",
        "        # Compute Error\n",
        "        ## MAE\n",
        "        error_stations['MAE'][z]=mean_absolute_error(stations[z], cell_values)\n",
        "        ## MSE\n",
        "        error_stations['MSE'][z]=mean_squared_error(stations[z], cell_values)\n",
        "        ## RMSE\n",
        "        error_stations['RMSE'][z]=sqrt(mean_squared_error(stations[z], cell_values))\n",
        "        ## Correlation\n",
        "        error_stations['Correlation'][z]=np.corrcoef(stations[z],cell_values)[0,1]\n",
        "        ## Mutual Information\n",
        "        error_stations['Mutual Information'][z]=calc_MI(stations[z],cell_values)\n",
        "        ## Cross Entropy\n",
        "        error_stations['Cross Entropy'][z]=cross_entropy(stations[z], cell_values) \n",
        "    # Save results to CSV\n",
        "    error_stations.to_csv(\"Results/Error to local stations/\"+name+'_daily.csv')\n",
        "    # Save locally the results\n",
        "    error_options.append(error_stations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metrics to evaluate\n",
        "metrics=['MAE','MSE','RMSE','Correlation','Mutual Information','Cross Entropy']\n",
        "# Possible datasets\n",
        "opt=len(dataset_name)\n",
        "error_options=[]\n",
        "for i in range(opt): # opt\n",
        "    # Load dataset\n",
        "    name=dataset_name[i]\n",
        "    print(name)\n",
        "    data=dataset[i]\n",
        "    lat_set=lats[i]\n",
        "    long_set=longs[i]\n",
        "    # Pre-allocate results\n",
        "    error_stations=coords.copy().drop(['Length'],axis=1)\n",
        "    error_stations[metrics]=np.nan\n",
        "    # Compute Results\n",
        "    stations_names= error_stations.index\n",
        "    for z in stations_names:\n",
        "        cell_lat=1;cell_lon=1\n",
        "        # Get stations location in cell grids \n",
        "        if lat_set[0]<lat_set[1]:\n",
        "            while cell_lat<=len(lat_set):\n",
        "                if (lat_set[cell_lat-1]+lat_set[cell_lat])/2<=error_stations['Lat'][z] and error_stations['Lat'][z]<=(lat_set[cell_lat+1]+lat_set[cell_lat])/2:\n",
        "                    break\n",
        "                cell_lat=cell_lat+1\n",
        "        else:\n",
        "            while cell_lat<=len(lat_set):\n",
        "                if (lat_set[cell_lat+1]+lat_set[cell_lat])/2<=error_stations['Lat'][z] and error_stations['Lat'][z]<=(lat_set[cell_lat-1]+lat_set[cell_lat])/2:\n",
        "                    break\n",
        "                cell_lat=cell_lat+1\n",
        "        while cell_lon<=len(long_set):\n",
        "            if (long_set[cell_lon-1]+long_set[cell_lon])/2<=error_stations['Long'][z] and error_stations['Long'][z]<=(long_set[cell_lon+1]+long_set[cell_lon])/2:\n",
        "                break\n",
        "            cell_lon=cell_lon+1\n",
        "        # Values in the cell where the station is located\n",
        "        cell_values=data[:,cell_lat,cell_lon]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Joined DataFrame\n",
        "data_join=pd.DataFrame(index=stations.index)\n",
        "data_join['Local']=stations[z]\n",
        "data_join['ERA5']=cell_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Error calculation to interpolation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ERA-Land vs IDW010"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Basin Mask 0.10 (.nc file)\n",
        "rain_nc=\"Data/Magdalena/GIS/Basin/Basin_ext_010.nc\"\n",
        "basin = nc.Dataset(rain_nc)\n",
        "basin_lat=basin.variables['lat'][:]\n",
        "basin_lon=basin.variables['lon'][:]\n",
        "var_type=list(basin.variables.keys())[0]  \n",
        "cells_x=np.array(basin_lat)[:]\n",
        "cells_y=np.array(basin_lon)[:]\n",
        "mascara=np.array(basin.variables[var_type][:,:])\n",
        "mask=mascara!=mascara[1,1]\n",
        "mask=np.flip(mask*1,axis=0).astype('float64')\n",
        "mask[mask==0]=np.nan\n",
        "mask_st=mask.reshape((1, mask.shape[0],mask.shape[1]))\n",
        "mask_basin=mask_st.reshape(mask_st.shape[1],mask_st.shape[2])\n",
        "basin.close()\n",
        "# Find coordinates where basin exists in mask\n",
        "basin_coords=np.where(mask_basin==1)\n",
        "# Find position of coordinates in datasets arrays\n",
        "basin_true_longs=basin_lon.data[basin_coords[1]]+360\n",
        "basin_true_lats=np.flip(basin_lat.data)[basin_coords[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metrics to evaluate\n",
        "metrics=['MAE','MSE','RMSE','Correlation','Mutual Information','Cross Entropy']\n",
        "# Pre-allocate results\n",
        "template=mask_basin*-9999\n",
        "mae_res=template.copy()\n",
        "mse_res=template.copy()\n",
        "rmse_res=template.copy()\n",
        "correlation_res=template.copy()\n",
        "mutinf_res=template.copy()\n",
        "cent_res=template.copy()\n",
        "# Iterate over basin pixels\n",
        "for j in range(len(basin_coords[0])):\n",
        "    # Array position \n",
        "    x_long=basin_coords[0][j]\n",
        "    y_lat=basin_coords[1][j]\n",
        "\n",
        "    # Geographic position\n",
        "    look_long=basin_true_longs[j]\n",
        "    look_lat=basin_true_lats[j]\n",
        "    \n",
        "    # IDW position:\n",
        "    ## Lat\n",
        "    lat_idw_pos=np.where((nc_lat_idw010==look_lat))\n",
        "    if len(lat_idw_pos[0])==0:\n",
        "        continue\n",
        "    lat_idw=lat_idw_pos[0]\n",
        "    ## Long\n",
        "    long_idw_pos=np.where((nc_lon_idw010==look_long))\n",
        "    if len(long_idw_pos[0])==0:\n",
        "        continue\n",
        "    long_idw=long_idw_pos[0]\n",
        "    \n",
        "    # ERA5 position:\n",
        "    ## Lat\n",
        "    lat_eraland_pos=np.where((nc_lat_eraland==look_lat))\n",
        "    if len(lat_eraland_pos[0])==0:\n",
        "        continue\n",
        "    lat_eraland=lat_eraland_pos[0]\n",
        "    ## Long\n",
        "    long_eraland_pos=np.where((nc_lon_eraland==look_long))\n",
        "    if len(long_eraland_pos[0])==0:\n",
        "        continue\n",
        "    long_eraland=long_eraland_pos[0]\n",
        "    \n",
        "    # Datasets values\n",
        "    ## IDW value\n",
        "    idw10_value=idw10[:,lat_idw,long_idw].flatten()\n",
        "    ## ERA5 value\n",
        "    eraland_value=eraland[:,lat_eraland,long_eraland].flatten()\n",
        "    \n",
        "    # Error calculation\n",
        "    ## MAE\n",
        "    mae_res[x_long,y_lat]=mean_absolute_error(idw10_value, eraland_value)\n",
        "    ## MSE\n",
        "    mse_res[x_long,y_lat]=mean_squared_error(idw10_value, eraland_value)\n",
        "    ## RMSE\n",
        "    rmse_res[x_long,y_lat]=sqrt(mean_squared_error(idw10_value, eraland_value))\n",
        "    ## Correlation\n",
        "    correlation_res[x_long,y_lat]=np.corrcoef(idw10_value,eraland_value)[0,1]\n",
        "    ## Mutual Information\n",
        "    mutinf_res[x_long,y_lat]=calc_MI(idw10_value,eraland_value)\n",
        "    ## Cross Entropy\n",
        "    cent_res[x_long,y_lat]=cross_entropy(idw10_value, eraland_value) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### SAVE results TO NC FILE ######\n",
        "metrics=['MAE','MSE','RMSE','Correlation','Mutual Information','Cross Entropy']\n",
        "res_list=[mae_res,mse_res,rmse_res,correlation_res,mutinf_res,cent_res]\n",
        "for i in range(len(metrics)):\n",
        "    # Define Path \n",
        "    name=metrics[i]+'_daily_010.nc'\n",
        "    ncfile = nc.Dataset(\"Error to interpolations/\"+name,mode='w',format='NETCDF3_64BIT_OFFSET') \n",
        "    # Creating dimensions\n",
        "    lat_dim = ncfile.createDimension('latitude',len(basin_lat))    \n",
        "    lon_dim = ncfile.createDimension('longitude',len(basin_lon) ) \n",
        "    ncfile.title=metrics[i]\n",
        "    lat = ncfile.createVariable('latitude', np.float32, ('latitude',))\n",
        "    lat.units = idw10nc.variables['latitude'].units\n",
        "    lon = ncfile.createVariable('longitude', np.float32, ('longitude',))\n",
        "    lon.units = idw10nc.variables['longitude'].units\n",
        "    rest_nc= ncfile.createVariable(metrics[i],np.float64,('latitude','longitude')) \n",
        "    rest_nc.missing_value=-9999\n",
        "    lat[:] = np.flip(basin_lat.data) \n",
        "    lon[:] = basin_lon \n",
        "    rest_nc[:,:] = res_list[i]\n",
        "    ncfile.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
